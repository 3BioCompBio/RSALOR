{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## RSALOR: Ready-to-Use Notebook\n",
        "[![PyPi Version](https://img.shields.io/pypi/v/rsalor.svg)](https://pypi.org/project/rsalor/) [![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
        "https://colab.research.google.com/github/3BioCompBio/RSALOR/blob/main/colab_notebook_RSALOR.ipynb)\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/3BioCompBio/RSALOR/main/Logo.png\" height=\"250\" align=\"right\" style=\"height:200px;\">\n",
        "\n",
        "Ready-to-Use Notebook to run the RSALOR model:\n",
        " - Upload or fetch an MSA file\n",
        " - Upload or fetch a 3D structure file\n",
        " - Run predictions on all single-site mutations\n",
        " - Visualize results\n",
        "\n",
        "The `rsalor` package combines structural data (Relative Solvent Accessibility, RSA) and evolutionary data (Log Odd Ratio, LOR from MSA) to evaluate effects of missense mutations in proteins.\n",
        "It computes the `RSA*LOR` score for each single-site missense mutation in a target protein by combining multiple computational steps into a fast and user-friendly tool.\n",
        "Source code in the [RSALOR GitHub](https://github.com/3BioCompBio/RSALOR).\n",
        "\n",
        "**Please cite**:\n",
        "- [Matsvei Tsishyn, Pauline Hermans, Fabrizio Pucci, Marianne Rooman (2025). Residue conservation and solvent accessibility are (almost) all you need for predicting mutational effects in proteins. Bioinformatics, btaf322](https://doi.org/10.1093/bioinformatics/btaf322).\n",
        "\n",
        "- [Pauline Hermans, Matsvei Tsishyn, Martin Schwersensky, Marianne Rooman, Fabrizio Pucci (2024). Exploring evolution to uncover insights into protein mutational stability. Molecular Biology and Evolution, 42(1), msae267](https://doi.org/10.1093/molbev/msae267)."
      ],
      "metadata": {
        "id": "igDhE0gKOOiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install dependencies\n",
        "\n",
        "%pip install rsalor\n",
        "%pip install requests"
      ],
      "metadata": {
        "cellView": "form",
        "id": "URoienkLfNsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzWtI1teMTTA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Imports and utility functions\n",
        "\n",
        "# Imports ----------------------------------------------------------------------\n",
        "import os\n",
        "import tarfile\n",
        "import time\n",
        "from typing import Callable\n",
        "import requests\n",
        "from requests import Response\n",
        "from google.colab import files\n",
        "from Bio.PDB import PDBParser, PDBList\n",
        "from Bio.PDB.Structure import Structure\n",
        "from rsalor import MSA\n",
        "from rsalor.sequence import Sequence, FastaReader, PairwiseAlignment, AminoAcid\n",
        "\n",
        "\n",
        "# Init paths -------------------------------------------------------------------\n",
        "# Set these paths to None to prevent the user to execute cells in incorrect order\n",
        "msa_path = None\n",
        "pdb_path = None\n",
        "chain = None\n",
        "output_path = None\n",
        "\n",
        "\n",
        "# Dependencies (small helper functions) ----------------------------------------\n",
        "def clip_string(input_str: str, max_len: int=100) -> str:\n",
        "  \"\"\"Truncate a string and append '...' if it exceeds max_len.\"\"\"\n",
        "  return input_str if len(input_str) <= max_len else input_str[:max_len] + \"...\"\n",
        "\n",
        "def extract_sequences(structure: Structure, pdb_name: str=\"pdb\") -> dict[str, Sequence]:\n",
        "  \"\"\"Extract the standardized amino acid sequence for each chain in the PDB Structure (uses only first model).\"\"\"\n",
        "  sequences_by_chain: dict[str, Sequence] = {}\n",
        "  for chain in structure[0]: # loop only on model 1\n",
        "    aa_seq: list[AminoAcid] = []\n",
        "    for residue in chain:\n",
        "      aa = AminoAcid.parse_three(residue.resname)\n",
        "      if aa.is_aminoacid() and not aa.is_unknown():\n",
        "        aa_seq.append(aa)\n",
        "    sequences_by_chain[str(chain.id)] = Sequence(f\"{pdb_name}_{chain.id}\", \"\".join(aa.one for aa in aa_seq))\n",
        "  return sequences_by_chain\n",
        "\n",
        "# Dependencies (fetch functions) -----------------------------------------------\n",
        "def is_valid_pdb_id(pdb_id :str) -> bool:\n",
        "  \"\"\"Returns if 'input' can be a PDB-ID.\"\"\"\n",
        "  POSSIBLE_FIRST_CHARACTERS = \"123456789\"\n",
        "  POSSIBLE_FOLLOWING_CHARACTERS = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "  input_upper = pdb_id.upper()\n",
        "  return len(input_upper) == 4 \\\n",
        "    and input_upper[0] in POSSIBLE_FIRST_CHARACTERS \\\n",
        "    and all([char in POSSIBLE_FOLLOWING_CHARACTERS for char in input_upper[1:]])\n",
        "\n",
        "def fetch_structure_by_pdb(pdb_id: str) -> str:\n",
        "  \"\"\"Fetch a '.pdb' file from the PDB and return its path.\"\"\"\n",
        "  pdb_id = pdb_id.lower().strip()\n",
        "  if not is_valid_pdb_id(pdb_id):\n",
        "    raise ValueError(f\"âŒ pdb_id='{pdb_id}' is not a valid PDB Id.\")\n",
        "  pdb_fetcher = PDBList()\n",
        "  file_path = pdb_fetcher.retrieve_pdb_file(pdb_id, file_format=\"pdb\", pdir=\"./\")\n",
        "  if file_path is None:\n",
        "    raise ValueError(f\"âŒ Fetch pdb_id='{pdb_id}' has failed.\")\n",
        "  if file_path.endswith(\".ent\"):\n",
        "    file_path_old = file_path\n",
        "    file_path = file_path.removesuffix(\".ent\") + \".pdb\"\n",
        "    os.rename(file_path_old, file_path)\n",
        "  return file_path\n",
        "\n",
        "def fetch_structure_by_uniprot(uniprot_id: str) -> str:\n",
        "  \"\"\"Fetch a '.pdb' file from the AlphaFoldDB by its UniProt ID and return its path.\"\"\"\n",
        "\n",
        "  # Init\n",
        "  uniprot_id = uniprot_id.upper().strip()\n",
        "  filename = f\"AF-{uniprot_id}-F1-model_v6.pdb\"\n",
        "  url = f\"https://alphafold.ebi.ac.uk/files/{filename}\"\n",
        "  print(f\" * fetch 3D structure from '{url}'\")\n",
        "\n",
        "  # Request structure\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "    r.raise_for_status()\n",
        "  except Exception as err:\n",
        "    raise ValueError(f\"âŒ AlphaFoldDB structure fetch failed for UniProt ID '{uniprot_id}' from '{url}': {err}\")\n",
        "\n",
        "  # Save structure and return path\n",
        "  with open(filename, \"wb\") as fs:\n",
        "    fs.write(r.content)\n",
        "  return filename\n",
        "\n",
        "def fetch_msa_by_uniprot(uniprot_id: str) -> str:\n",
        "  \"\"\"Fetch an MSA file from the AlphaFoldDB by its UniProt ID and return its path.\"\"\"\n",
        "\n",
        "  # Init\n",
        "  uniprot_id = uniprot_id.upper().strip()\n",
        "  filename = f\"AF-{uniprot_id}-F1-msa_v6.a3m\"\n",
        "  url = f\"https://alphafold.ebi.ac.uk/files/msa/{filename}\"\n",
        "  print(f\" * fetch MSA from '{url}'\")\n",
        "\n",
        "  # Steam and write MSA to file and return path\n",
        "  try:\n",
        "    with requests.get(url, stream=True) as resp:\n",
        "      resp.raise_for_status()\n",
        "      with open(filename, \"wb\") as fs:\n",
        "        for chunk in resp.iter_content(1 << 14): # 16 KB chunks\n",
        "          if chunk:\n",
        "            fs.write(chunk)\n",
        "  except Exception as err:\n",
        "    raise ValueError(f\"âŒ AlphaFoldDB MSA fetch failed for UniProt ID '{uniprot_id}': download failed from '{url}': {err}\")\n",
        "  return filename\n",
        "\n",
        "def fetch_sequence_by_uniprot(uniprot_id: str) -> str:\n",
        "  \"\"\"Fetch an FASTA sequence from UniProt by its UniProt ID and return its path.\"\"\"\n",
        "\n",
        "  # Init\n",
        "  uniprot_id = uniprot_id.upper().strip()\n",
        "  filename = f\"{uniprot_id}.fasta\"\n",
        "  url = f\"https://rest.uniprot.org/uniprotkb/{filename}\"\n",
        "  print(f\" * fetch FASTA sequence from '{url}'\")\n",
        "\n",
        "  # Request fasta\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "    r.raise_for_status()\n",
        "  except Exception as err:\n",
        "    raise ValueError(f\"âŒ UniProt FASTA sequence fetch failed for UniProt ID '{uniprot_id}' from '{url}': {err}\")\n",
        "\n",
        "  # Save fasta and return path\n",
        "  with open(filename, \"wb\") as fs:\n",
        "    fs.write(r.content)\n",
        "  return filename\n",
        "\n",
        "# Dependencies (MMSeqs2 API) ---------------------------------------------------\n",
        "\n",
        "def repeated_request(request_function: Callable):\n",
        "  \"\"\"Decorator to repeat a request 5 times before trowing an error.\"\"\"\n",
        "\n",
        "  def wrapper(*args, **kwargs) -> Response:\n",
        "    MAX_REQUEST_TRIES = 5\n",
        "    FAIL_SLEEP_TIME = 5.0\n",
        "    print(f\" * Request [{request_function.__name__}] for '{clip_string(args[0])}' ({MAX_REQUEST_TRIES} repeats)\")\n",
        "    for i in range(MAX_REQUEST_TRIES):\n",
        "      print(f\"   - [{request_function.__name__}] repeat [{i+1}/{MAX_REQUEST_TRIES}] ...\")\n",
        "      try:\n",
        "        res: Response = request_function(*args, **kwargs)\n",
        "      except Exception as err:\n",
        "        print(f\"   - [{request_function.__name__}] Error on attempt [{i+1}/{MAX_REQUEST_TRIES}]: {err}\")\n",
        "        time.sleep(FAIL_SLEEP_TIME)\n",
        "      else:\n",
        "        print(f\"   - [{request_function.__name__}] status: {res.status_code}\")\n",
        "        return res\n",
        "    raise ValueError(f\"Too many failed attempts ({MAX_REQUEST_TRIES}) for request '{request_function.__name__}'.\")\n",
        "\n",
        "  return wrapper\n",
        "\n",
        "def json_request(request_function: Callable):\n",
        "  \"\"\"Decorator run a request and parse output as JSON if possible.\"\"\"\n",
        "\n",
        "  def wrapper(*args, **kwargs):\n",
        "    res: Response = request_function(*args, **kwargs)\n",
        "    try:\n",
        "      return res.json()\n",
        "    except Exception as err:\n",
        "      msg = (\n",
        "        f\"Failed to parse response from '{request_function.__name__}' as JSON.\\n\"\n",
        "        f\"Original error: {err}\\n\"\n",
        "        f\"HTTP status: {res.status_code}\\n\"\n",
        "        f\"Response (truncated): {clip_string(res.text)}\"\n",
        "      )\n",
        "      raise ValueError(msg) from err\n",
        "\n",
        "  return wrapper\n",
        "\n",
        "@json_request\n",
        "@repeated_request\n",
        "def submit_mmseqs2(seq: str, mode: str, url: str, endpoint: str, timeout: float, query_name: str=\"query\"):\n",
        "  query_name = query_name.strip().replace(\" \", \"_\").replace(\"\\t\", \"_\").replace(\"\\n\", \"_\")\n",
        "  assert len(query_name) > 0, f\"ERROR in submit_mmseqs2(): invalid query_name='{query_name}'\"\n",
        "  return requests.post(\n",
        "    f\"{url}/{endpoint}\",\n",
        "    data={\"q\": f\">{query_name}\\n{seq}\\n\", \"mode\": mode},\n",
        "    timeout=timeout,\n",
        "  )\n",
        "\n",
        "@json_request\n",
        "@repeated_request\n",
        "def get_mmseqs2_status(id: str, url: str, timeout: float):\n",
        "  res = requests.get(\n",
        "    f\"{url}/ticket/{id}\",\n",
        "    timeout=timeout,\n",
        "  )\n",
        "  return res\n",
        "\n",
        "@repeated_request\n",
        "def download_from_mmseqs2(id: str, url: str, timeout: float) -> Response:\n",
        "  res = requests.get(\n",
        "    f\"{url}/result/download/{id}\",\n",
        "    timeout=timeout,\n",
        "  )\n",
        "  return res\n",
        "\n",
        "class MMSeqs2API:\n",
        "\n",
        "  # Constructor\n",
        "  def __init__(\n",
        "    self,\n",
        "    tmp_dir: str,\n",
        "    n_status_loop: int=100,\n",
        "    loop_timeout: float = 5.0,\n",
        "    single_request_timeout: float=6.02,\n",
        "    use_env: bool = False,\n",
        "    use_filter: bool = True,\n",
        "    url: str=\"https://api.colabfold.com\",\n",
        "    endpoint: str=\"ticket/msa\",\n",
        "  ):\n",
        "\n",
        "    # Set properties\n",
        "    self.tmp_dir = tmp_dir\n",
        "    self.url = url\n",
        "    self.endpoint = endpoint\n",
        "    self.n_status_loop = n_status_loop\n",
        "    self.loop_timeout = loop_timeout\n",
        "    self.single_request_timeout = single_request_timeout\n",
        "    self.use_env = use_env\n",
        "    self.use_filter = use_filter\n",
        "    if self.use_filter:\n",
        "      self.mode = \"env\" if self.use_env else \"all\"\n",
        "    else:\n",
        "      self.mode = \"env-nofilter\" if self.use_env else \"nofilter\"\n",
        "\n",
        "    # Init tmp directory\n",
        "    if not os.path.isdir(self.tmp_dir):\n",
        "      os.mkdir(self.tmp_dir)\n",
        "\n",
        "    # Init paths\n",
        "    self.tar_gz_file = os.path.join(self.tmp_dir, \"out.tar.gz\")\n",
        "    if not self.use_env:\n",
        "      self.a3m_files = [os.path.join(self.tmp_dir, \"uniref.a3m\")]\n",
        "    else:\n",
        "      self.a3m_files = [\n",
        "        os.path.join(self.tmp_dir, \"uniref.a3m\"),\n",
        "        os.path.join(self.tmp_dir, \"bfd.mgnify30.metaeuk30.smag30.a3m\")\n",
        "      ]\n",
        "\n",
        "  # Run API\n",
        "  def run(\n",
        "    self,\n",
        "    sequence: str,\n",
        "    save_path: str,\n",
        "    query_name: str=\"query\",\n",
        "  ) -> str:\n",
        "\n",
        "    # Log\n",
        "    print(f\"Run MSA API to MMSeqs2 server '{self.url}/{self.endpoint}': \")\n",
        "    print(f\"   - sequence: '{clip_string(sequence)}'\")\n",
        "    print(f\"   - save_path: '{save_path}'\")\n",
        "\n",
        "    # Submit to MMSeqs2 API\n",
        "    print(\"Submit request:\")\n",
        "    out = submit_mmseqs2(sequence, self.mode, self.url, self.endpoint, self.single_request_timeout, query_name=query_name)\n",
        "    status, id = out[\"status\"], out[\"id\"]\n",
        "    if status in [\"ERROR\", \"MAINTENANCE\"]:\n",
        "      raise Exception(f\"MMseqs2 API is giving errors with API status: '{status}' (please try again later)\")\n",
        "\n",
        "    # Wait for request to be completed\n",
        "    print(\"Wait for request to be completed:\")\n",
        "    for i in range(self.n_status_loop):\n",
        "      if status not in [\"UNKNOWN\", \"RUNNING\", \"PENDING\"]:\n",
        "        break\n",
        "      print(f\"   - sleep [{i+1}/{self.n_status_loop}] for {self.loop_timeout:.1f} sec. (status='{status}') ...\")\n",
        "      time.sleep(self.loop_timeout)\n",
        "      out = get_mmseqs2_status(id, self.url, self.single_request_timeout)\n",
        "      status = out[\"status\"]\n",
        "\n",
        "    # Status loop finished and request still not complete\n",
        "    if status in [\"UNKNOWN\", \"RUNNING\", \"PENDING\"]:\n",
        "      msg = (\n",
        "        f\"MMseqs2 API ERROR: maximum number of sleep loop exceeded.\\n\"\n",
        "        f\" - {self.n_status_loop} loops (of {self.loop_timeout:.1f} sec. each)\\n\"\n",
        "        f\" - request ID='{id}'\\n\"\n",
        "      )\n",
        "      raise Exception(msg)\n",
        "\n",
        "    # Final API status check\n",
        "    if status != \"COMPLETE\":\n",
        "      raise Exception(f\"MMseqs2 API is giving errors with API status: '{status}' (please try again later)\")\n",
        "\n",
        "    # Download results\n",
        "    print(\"Download MSA:\")\n",
        "    download_output = download_from_mmseqs2(id, self.url, self.single_request_timeout)\n",
        "    with open(self.tar_gz_file, \"wb\") as fs:\n",
        "      fs.write(download_output.content)\n",
        "\n",
        "    # Extract a3m files from '.tar.gz'\n",
        "    print(f\"Collect MSA data:\")\n",
        "    with tarfile.open(self.tar_gz_file) as tar_gz:\n",
        "      tar_gz.extractall(self.tmp_dir, filter=\"data\")\n",
        "\n",
        "    # Collect and return all '.a3m' lines\n",
        "    a3m_lines: list[str] = []\n",
        "    for a3m_file in self.a3m_files:\n",
        "      for line in open(a3m_file, \"r\"):\n",
        "        if len(line) == 0: continue\n",
        "        line = line.replace(\"\\x00\", \"\")\n",
        "        a3m_lines.append(line)\n",
        "    msa_str = \"\".join(a3m_lines)\n",
        "\n",
        "    # Save MSA to file\n",
        "    print(f\"Save MSA to file:\")\n",
        "    print(f\"   - save_path: '{save_path}'\")\n",
        "    with open(save_path, \"w\") as fs:\n",
        "      fs.write(msa_str)\n",
        "\n",
        "    # Return\n",
        "    return save_path\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3D Structure options (upload file or fetch from PDB or AlphaFold-DB)\n",
        "\n",
        "# Define upload method ---------------------------------------------------------\n",
        "upload_method = \"upload_local_file\" # @param [\"upload_local_file\",\"fetch_from_pdb\",\"fetch_from_alphafold_db\"]\n",
        "#@markdown ---------------------------------------------------------------------\n",
        "retrieval_id = \"\" # @param {\"type\":\"string\",\"placeholder\":\"PDB ID like '6m0j' or UniProt ID like 'Q9LW00'\"}\n",
        "#@markdown - if using `fetch_from_pdb`, specify a **PDB ID** (like `6m0j`)\n",
        "#@markdown - if using `fetch_from_alphafold_db`, specify a **UniProt ID** (like `Q9LW00`)\n",
        "\n",
        "\n",
        "# Case: Drag-and-drop local file -----------------------------------------------\n",
        "pdb_path = None\n",
        "if upload_method == \"upload_local_file\":\n",
        "\n",
        "  # Drag-and-drop file picker\n",
        "  uploaded = files.upload()\n",
        "  pdb_path: str = list(uploaded.keys())[0]\n",
        "\n",
        "  # Guardian for correct extension\n",
        "  if not pdb_path.endswith(\".pdb\"):\n",
        "    pdb_path_failed = pdb_path\n",
        "    pdb_path = None\n",
        "    raise ValueError(f\"âŒ Uploaded PDB file '{pdb_path_failed}' should have extention '.pdb'.\")\n",
        "  pdb_name = pdb_path.removesuffix(\".pdb\")\n",
        "  print(f\" * âœ… PDB file uploaded: '{pdb_path}'\")\n",
        "\n",
        "# Case: fetch file from the PDB ------------------------------------------------\n",
        "elif upload_method == \"fetch_from_pdb\":\n",
        "\n",
        "  # retrieval_id not fill error\n",
        "  if retrieval_id == \"\" or retrieval_id is None:\n",
        "    raise ValueError(f\"âŒ If upload_method='{upload_method}', please specify a retrieval_id.\")\n",
        "\n",
        "  # Fetch PDB file\n",
        "  pdb_path: str = fetch_structure_by_pdb(retrieval_id)\n",
        "  pdb_name = pdb_path.removesuffix(\".pdb\")\n",
        "  print(f\" * âœ… PDB file fetched: '{pdb_path}'\")\n",
        "\n",
        "# Case: fetch file from the AlphaFold-DB ---------------------------------------\n",
        "elif upload_method == \"fetch_from_alphafold_db\":\n",
        "\n",
        "  # retrieval_id not fill error\n",
        "  if retrieval_id == \"\" or retrieval_id is None:\n",
        "    raise ValueError(f\"âŒ If upload_method='{upload_method}', please specify a retrieval_id.\")\n",
        "\n",
        "  # Fetch PDB file\n",
        "  pdb_path: str = fetch_structure_by_uniprot(retrieval_id)\n",
        "  pdb_name = pdb_path.removesuffix(\".pdb\")\n",
        "  print(f\" * âœ… AF-DB file fetched: '{pdb_path}'\")\n",
        "\n",
        "# Case: error ------------------------------------------------------------------\n",
        "else:\n",
        "  raise ValueError(f\"âŒ Unknown upload_method='{upload_method}'.\")\n",
        "\n",
        "# Validate and Log -------------------------------------------------------------\n",
        "# Parse PDB file\n",
        "structure = PDBParser(QUIET=True).get_structure(\"protein\", pdb_path)\n",
        "\n",
        "# Log uploaded PDB file\n",
        "sequences_by_chain = extract_sequences(structure, pdb_name)\n",
        "print(f\" * âœ… Choose target chain among {len(sequences_by_chain)} detected chain(s): '{''.join(sequences_by_chain.keys())}'\")\n",
        "for chain, seq in sequences_by_chain.items():\n",
        "  print(f\"    - chain {chain} (L={len(seq)}): '{seq.sequence}'\")\n",
        "\n",
        "# Select chain if there is only one\n",
        "if len(sequences_by_chain) == 1:\n",
        "  chain = list(sequences_by_chain.keys())[0]\n",
        "  print(f\" * âœ… Target chain set to: chain='{chain}'\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "O6dopoi7ivAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title MSA options (upload file, fetch from AlphaFold-DB or run MMSeqs2 API)\n",
        "\n",
        "# Define upload method ---------------------------------------------------------\n",
        "upload_method = \"upload_local_file\" # @param [\"upload_local_file\",\"fetch_from_alphafold_db\",\"run_mmseqs2_api\"]\n",
        "#@markdown ---------------------------------------------------------------------\n",
        "uniprot_id = \"\" # @param {\"type\":\"string\",\"placeholder\":\"UniProt ID like 'Q9LW00'\"}\n",
        "#@markdown - if using `fetch_from_alphafold_db`, specify a **UniProt ID** (like `Q9LW00`)\n",
        "#@markdown ---------------------------------------------------------------------\n",
        "query_sequence = \"\" # @param {\"type\":\"string\",\"placeholder\":\"protein sequence like 'VSVELPAPSSWKKLFYPNKVGSVKKTEVVFVAPTGEEISNRKQLEQYLKSHPGNPAIAEFDWTTSG'\"}\n",
        "#@markdown - if using `run_mmseqs2_api`, specify a protein sequence\n",
        "query_name = \"query_sequence_1\" # @param {\"type\":\"string\",\"placeholder\":\"set name of the query sequence\"}\n",
        "mmseqs2_use_filtering = True # @param {\"type\":\"boolean\"}\n",
        "mmseqs2_use_environmental_sequences = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "# Case: Drag-and-drop local file -----------------------------------------------\n",
        "msa_path = None\n",
        "if upload_method == \"upload_local_file\":\n",
        "\n",
        "  # Drag-and-drop file picker\n",
        "  uploaded = files.upload()\n",
        "  msa_path: str = list(uploaded.keys())[0]\n",
        "\n",
        "  # Guardian for correct extension\n",
        "  if not any(msa_path.endswith(ext) for ext in MSA.ACCEPTED_EXTENTIONS):\n",
        "      msa_path_failed = msa_path\n",
        "      msa_path = None\n",
        "      raise ValueError(f\"âŒ Uploaded MSA file '{msa_path_failed}' should have extention among {MSA.ACCEPTED_EXTENTIONS}.\")\n",
        "  print(f\" * âœ… MSA file uploaded: '{msa_path}'\")\n",
        "\n",
        "# Case: fetch file from the AlphaFold-DB ---------------------------------------\n",
        "elif upload_method == \"fetch_from_alphafold_db\":\n",
        "\n",
        "  # retrieval_id not fill error\n",
        "  if uniprot_id == \"\" or uniprot_id is None:\n",
        "    raise ValueError(f\"âŒ If upload_method='{upload_method}', please specify a uniprot_id.\")\n",
        "\n",
        "  # Fetch PDB file\n",
        "  msa_path: str = fetch_msa_by_uniprot(uniprot_id)\n",
        "  print(f\" * âœ… MSA file fetched from AF-DB: '{msa_path}'\")\n",
        "\n",
        "# Case: run MMSeqs2 API --------------------------------------------------------\n",
        "elif upload_method == \"run_mmseqs2_api\":\n",
        "\n",
        "  # Pre-process query_sequence\n",
        "  query_sequence = query_sequence.strip().replace(\" \", \"\").upper()\n",
        "  if query_sequence == \"\" or query_sequence is None:\n",
        "    raise ValueError(f\"âŒ If upload_method='{upload_method}', please specify a query_sequence.\")\n",
        "  if not all([aa in \"ACDEFGHIKLMNPQRSTVWY\" for aa in query_sequence]):\n",
        "    raise ValueError(f\"âŒ query_sequence contains invalid amino acids.\")\n",
        "  query_name = query_name.strip().replace(\" \", \"_\")\n",
        "  if query_name == \"\" or query_name is None:\n",
        "    raise ValueError(f\"âŒ If upload_method='{upload_method}', please specify a query_name.\")\n",
        "\n",
        "  # Run MMSeqs2 API\n",
        "  api = MMSeqs2API(\n",
        "    f\"./{query_name}_mmseqs2_out\",\n",
        "    use_env=mmseqs2_use_environmental_sequences,\n",
        "    use_filter=mmseqs2_use_filtering,\n",
        "  )\n",
        "  msa_path: str = api.run(query_sequence, f\"./{query_name}.a3m\", query_name)\n",
        "  print(f\" * âœ… MSA file obtained from MMSeqs2 API: '{msa_path}'\")\n",
        "\n",
        "# Case: error ------------------------------------------------------------------\n",
        "else:\n",
        "  raise ValueError(f\"âŒ Unknown upload_method='{upload_method}'.\")\n",
        "\n",
        "# Validate and Log -------------------------------------------------------------\n",
        "taget_sequence = FastaReader.read_first_sequence(msa_path)\n",
        "print(f\" * âœ… taget sequence (L={len(taget_sequence)}): '{taget_sequence.sequence}'\")\n",
        "\n"
      ],
      "metadata": {
        "id": "iKcd15dHQySw",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select PDB chain\n",
        "chain = \"\" # @param {\"type\":\"string\",\"placeholder\":\"select a single chains like 'A'\"}\n",
        "\n",
        "# Input guardians\n",
        "if msa_path == \"\" or msa_path is None:\n",
        "  raise ValueError(f\"âŒ ERROR: msa_path is not set: Please first select an MSA.\")\n",
        "if pdb_path == \"\" or pdb_path is None:\n",
        "  raise ValueError(f\"âŒ ERROR: pdb_path is not set: Please first, select a 3D structure.\")\n",
        "\n",
        "# Guardians\n",
        "if len(chain) != 1:\n",
        "  chain_failed = chain\n",
        "  chain = None\n",
        "  raise ValueError(f\"âŒ chain='{chain_failed}' should be a string of length 1.\")\n",
        "if chain not in sequences_by_chain:\n",
        "  chain_failed = chain\n",
        "  chain = None\n",
        "  raise ValueError(f\"âŒ chain='{chain_failed}' not in PDB '{pdb_path}' (among chains '{''.join(sequences_by_chain.keys())}')\")\n",
        "\n",
        "# Show alignments\n",
        "print(f\" * âœ… MSA target sequence aligned to chain '{chain}' in PDB structure.\")\n",
        "align = PairwiseAlignment(taget_sequence, sequences_by_chain[chain])\n",
        "align.show();\n",
        "\n",
        "# Not perfect alignments warning\n",
        "if align.match_ratio == 1.0:\n",
        "  print(f\" * âœ… Perfect alignment between MSA-sequence vs. 3D-structure.\")\n",
        "else:\n",
        "  all_chains = \"\".join(list(sequences_by_chain.keys()))\n",
        "  msg = (\n",
        "      f\"\\nâš ï¸ WARNING: MSA-sequence vs. 3D-structure alignment is not perfect: \\n\"\n",
        "      f\"    - ðŸŸ¢ match:         {align.match} \\n\"\n",
        "      f\"    - ðŸŸ¡ tail gaps:     {align.tail_gap} \\n\"\n",
        "      f\"    - ðŸŸ  internal gaps: {align.internal_gap} \\n\"\n",
        "      f\"    - ðŸ”´ mismatch:      {align.mismatch} \\n\"\n",
        "      f\" -> Please verify if selected chain '{chain}' is correct (among chains '{all_chains}')\"\n",
        "  )\n",
        "  print(msg)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yTKvX4WCz9W9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run RSALOR and Settings\n",
        "\n",
        "# Output settings\n",
        "#@markdown ### Output settings\n",
        "output_name = \"\" # @param {\"type\":\"string\",\"placeholder\":\"<msa_name>_rsalor\"}\n",
        "#@markdown - leave empty for auto\n",
        "sep = \",\" # @param {\"type\":\"string\",\"placeholder\":\"CSV separator like ',' or ';'\"}\n",
        "#@markdown - separator in output CSV file\n",
        "\n",
        "# RSALOR run settings\n",
        "#@markdown ---------------------------------------------------------------------\n",
        "#@markdown ### RSALOR settings\n",
        "theta_regularization = 0.01 # @param {\"type\":\"number\",\"placeholder\":\"0.01\"}\n",
        "#@markdown - regularization term for LOR/LR at amino acid frequencies level\n",
        "seqid_weights = 0.80 # @param {\"type\":\"number\",\"placeholder\":\"0.80\"}\n",
        "#@markdown - seqid threshold to consider two sequences in the same cluster for weighting (leave empty to ignore)\n",
        "min_seqid = 0.35 # @param {\"type\":\"number\",\"placeholder\":\"0.35\"}\n",
        "#@markdown - discard sequences which seqid with target sequence is below (leave empty to ignore)\n",
        "num_threads = 2 # @param {\"type\":\"integer\",\"placeholder\":\"2\"}\n",
        "#@markdown - number of threads (CPUs) for weights evaluation (in the C++ backend)\n",
        "\n",
        "# Input guardians\n",
        "if msa_path == \"\" or msa_path is None:\n",
        "  raise ValueError(f\"âŒ ERROR: msa_path is not set: Please first select an MSA.\")\n",
        "if pdb_path == \"\" or pdb_path is None:\n",
        "  raise ValueError(f\"âŒ ERROR: pdb_path is not set: Please first, select a 3D structure.\")\n",
        "if chain == \"\" or chain is None:\n",
        "  raise ValueError(f\"âŒ ERROR: chain is not set: Please first, select a chain.\")\n",
        "\n",
        "# Run RSALOR\n",
        "output_path = None\n",
        "msa = MSA(\n",
        "    msa_path, pdb_path, chain,\n",
        "    theta_regularization=theta_regularization,\n",
        "    seqid_weights=seqid_weights,\n",
        "    min_seqid=min_seqid,\n",
        "    num_threads=num_threads,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Set output path\n",
        "if output_name == \"\" or output_name is None:\n",
        "  output_name = f\"{msa.name}_rsalor\"\n",
        "output_path = f\"{output_name}.csv\"\n",
        "\n",
        "# Compute and save scores\n",
        "rsalor_scores = msa.save_scores(\n",
        "    output_path,\n",
        "    sep=sep,\n",
        "    round_digit=6,\n",
        "    log_results=False,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ebp05L4F7p3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download RSALOR output\n",
        "\n",
        "# Input guardians\n",
        "if output_path == \"\" or output_path is None:\n",
        "  raise ValueError(f\"âŒ ERROR: output_path is not set: Please first run RSALOR.\")\n",
        "\n",
        "# Download\n",
        "files.download(output_path)\n",
        "print(f\"âœ… RSALOR output file '{output_path}' downloaded.\")"
      ],
      "metadata": {
        "id": "KmW_SkOqEGuG",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Heatmap of RSALOR mutational predictions\n",
        "\n",
        "\n",
        "# Input guardians --------------------------------------------------------------\n",
        "if output_path == \"\" or output_path is None:\n",
        "  raise ValueError(f\"âŒ ERROR: msa object not defined: Please first run RSALOR.\")\n",
        "\n",
        "\n",
        "# Imports ----------------------------------------------------------------------\n",
        "import shutil\n",
        "import numpy as np\n",
        "from numpy.typing import NDArray\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "\n",
        "# Init heatmap folder ----------------------------------------------------------\n",
        "heatmap_dir = f\"{msa.name}_heatmaps\"\n",
        "if not os.path.isdir(heatmap_dir):\n",
        "  os.mkdir(heatmap_dir)\n",
        "\n",
        "\n",
        "# Plot Settings ----------------------------------------------------------------\n",
        "\n",
        "# Sizes settings\n",
        "CELL_SIZE = 60\n",
        "DPI = 100\n",
        "MIN_SIZE = 25\n",
        "RANGE_SIZE = 100\n",
        "TICKS_FONTSIZE = 20\n",
        "VAL_FONTSIZE = 12\n",
        "NOTE_FONTSIZE = 22\n",
        "\n",
        "# Colors\n",
        "color_fill = (0.90, 0.90, 0.90)\n",
        "\n",
        "cmap_rsa = mcolors.LinearSegmentedColormap.from_list(\n",
        "    \"RSA\",\n",
        "    [\n",
        "        (0.0, 0.373, 0.451), # burried (deep blue)\n",
        "        (1.0, 1.0, 1.0),     # eposed (white)\n",
        "    ],\n",
        ")\n",
        "cmap_rsa.set_bad(color=color_fill)\n",
        "\n",
        "cmap_gap_ratio = mcolors.LinearSegmentedColormap.from_list(\n",
        "    \"gap_ratio\",\n",
        "    [\n",
        "        (0.000, 0.325, 0.839),  # high confidence, dark blue\n",
        "        (0.396, 0.796, 0.953),  # medium-high confidence, light blue\n",
        "        (1.000, 0.859, 0.750),  # medium-low confidence, yellow\n",
        "        (1.000, 0.490, 0.271),  # low confidence, orange\n",
        "        (1.000, 0.271, 0.271),  # low confidence, red\n",
        "    ],\n",
        ")\n",
        "cmap_gap_ratio.set_bad(color=color_fill)\n",
        "\n",
        "cmap_plddt = mcolors.ListedColormap([\n",
        "    (1.000, 0.490, 0.271),  # AF-Color 1 (low confidence, orange)\n",
        "    (1.000, 0.859, 0.750),  # AF-Color 2 (medium-low confidence, yellow)\n",
        "    (0.396, 0.796, 0.953),  # AF-Color 3 (medium-high confidence, light blue)\n",
        "    (0.000, 0.325, 0.839)   # AF-Color 4 (high confidence, dark blue)\n",
        "])\n",
        "cmap_plddt.set_bad(color=color_fill)\n",
        "norm_plddt = mcolors.BoundaryNorm([0, 50, 70, 90, 100], cmap_plddt.N)\n",
        "\n",
        "cmap = plt.get_cmap('RdBu').reversed()\n",
        "cmap.set_bad(color=color_fill)\n",
        "\n",
        "\n",
        "# Extract RSALOR values --------------------------------------------------------\n",
        "\n",
        "# Base properties\n",
        "aas = [aa.one for aa in AminoAcid.get_all()]\n",
        "A = len(aas)\n",
        "L = msa.length\n",
        "Ntot = msa.depth\n",
        "sequence = msa.target_sequence.sequence\n",
        "\n",
        "# Log\n",
        "print(\"Plot Heatmap of RSALOR mutational predictions\")\n",
        "print(f\" âœ… MSA: '{clip_string(msa.name)}' (L={L}, N={Ntot})\")\n",
        "\n",
        "# Extract all values\n",
        "scores_map = {m[\"mutation_fasta\"]: m for m in rsalor_scores}\n",
        "plddt = np.full(L, np.nan, dtype=np.float32)\n",
        "rsa = np.full(L, np.nan, dtype=np.float32)\n",
        "gap_perc = np.full(L, np.nan, dtype=np.float32)\n",
        "lor_vector = np.full(L, np.nan, dtype=np.float32)\n",
        "rsalor_vector = np.full(L, np.nan, dtype=np.float32)\n",
        "lor_matrix = np.full((A, L), np.nan, dtype=np.float32)\n",
        "rsalor_matrix = np.full((A, L), np.nan, dtype=np.float32)\n",
        "for i, wt_aa in enumerate(sequence):\n",
        "  lor_arr: list[float] = []\n",
        "  rsalor_arr: list[float] = []\n",
        "  for j, mt_aa in enumerate(aas):\n",
        "    mut = f\"{wt_aa}{str(i+1)}{mt_aa}\"\n",
        "    mut_scores = scores_map[mut]\n",
        "    plddt[i] = mut_scores[\"pLDDT\"]\n",
        "    rsa[i] = mut_scores[\"RSA\"]\n",
        "    gap_perc[i] = mut_scores[\"gap_freq\"] * 100.0\n",
        "    lor = mut_scores[\"LOR\"]\n",
        "    rsalor = mut_scores[\"RSA*LOR\"]\n",
        "    lor_matrix[j, i] = lor\n",
        "    rsalor_matrix[j, i] = rsalor\n",
        "    if lor is not None:\n",
        "      lor_arr.append(lor)\n",
        "    if rsalor is not None:\n",
        "      rsalor_arr.append(rsalor)\n",
        "  if len(lor_arr) > 0:\n",
        "    lor_vector[i] = np.mean(lor_arr)\n",
        "  if len(rsalor_arr) > 0:\n",
        "    rsalor_vector[i] = np.mean(rsalor_arr)\n",
        "lor_extreme_val = np.nanmax(np.abs(lor_matrix))\n",
        "rsalor_extreme_val = np.nanmax(np.abs(rsalor_matrix))\n",
        "\n",
        "# Plot Heatmap -----------------------------------------------------------------\n",
        "\n",
        "# Init\n",
        "predictions_data = [\n",
        "    (\"RSALOR\", rsalor_matrix, rsalor_vector, rsalor_extreme_val),\n",
        "    (\"LOR\", lor_matrix, lor_vector, lor_extreme_val),\n",
        "]\n",
        "\n",
        "# Loop on different predictions (RSALOR and LOR)\n",
        "for prediction, matrix, mean_vector, extreme_val in predictions_data:\n",
        "\n",
        "  # Log\n",
        "  print(\"\\n-----------------------------------------------------------------------\")\n",
        "  print(f\"> {prediction}: \")\n",
        "\n",
        "  # Compute segments ranges (split heatmap if sequence is too long)\n",
        "  segments: list[tuple[int, int]] = []\n",
        "  segment_start = 0\n",
        "  while segment_start + RANGE_SIZE < L:\n",
        "      segments.append((segment_start, segment_start + RANGE_SIZE))\n",
        "      segment_start += RANGE_SIZE\n",
        "  segments.append((segment_start, L))\n",
        "\n",
        "  # Loop on segments\n",
        "  for n_seg, segment in enumerate(segments):\n",
        "\n",
        "    # Get measures on segment\n",
        "    start, end = segment\n",
        "    sequence_seg = sequence[start:end]\n",
        "    L_seg = len(sequence_seg)\n",
        "    gap_perc_seg = gap_perc[start:end]\n",
        "    plddt_seg = plddt[start:end]\n",
        "    rsa_seg = rsa[start:end]\n",
        "    vector_seg = mean_vector[start:end]\n",
        "    matrix_seg = matrix[:, start:end]\n",
        "    SEGMENT_SIZE = RANGE_SIZE\n",
        "    if len(segments) == 1:\n",
        "      SEGMENT_SIZE = max(L_seg, MIN_SIZE)\n",
        "    print(f\"\\n    - Range [{n_seg+1}/{len(segments)}]: {start+1} - {end}\")\n",
        "\n",
        "    # Init plot\n",
        "    fig_width = (SEGMENT_SIZE+9) * CELL_SIZE / DPI\n",
        "    fig_height = (A+4) * CELL_SIZE / DPI\n",
        "    fig = plt.figure(figsize=(fig_width*1.01, fig_height*1.10), dpi=DPI)\n",
        "    gs = gridspec.GridSpec(nrows=5, ncols=1, height_ratios=[1, 1, 1, 1, A])\n",
        "    ax_gap = fig.add_subplot(gs[0])\n",
        "    ax_plddt = fig.add_subplot(gs[1])\n",
        "    ax_rsa = fig.add_subplot(gs[2])\n",
        "    ax_avg = fig.add_subplot(gs[3])\n",
        "    ax0 = fig.add_subplot(gs[4])\n",
        "\n",
        "    # Plot gap ratio\n",
        "    ax_gap.set_xticks([])\n",
        "    ax_gap.set_yticks([0])\n",
        "    ax_gap.set_yticklabels([\"gap %\"], fontsize=TICKS_FONTSIZE)\n",
        "    gap_perc_seg_ = np.full(SEGMENT_SIZE, np.nan)\n",
        "    gap_perc_seg_[:L_seg] = gap_perc_seg\n",
        "    im_gap = ax_gap.imshow(np.array([gap_perc_seg_]), cmap=cmap_gap_ratio, vmin=0, vmax=100, aspect='equal')\n",
        "    for i, i_gap in enumerate(gap_perc_seg):\n",
        "      ax_gap.text(\n",
        "        i, 0, str(int(i_gap)),\n",
        "        ha='center', va='center',\n",
        "        fontsize=VAL_FONTSIZE,\n",
        "      )\n",
        "\n",
        "    # Plot plddt\n",
        "    ax_plddt.set_xticks([])\n",
        "    ax_plddt.set_yticks([0])\n",
        "    ax_plddt.set_yticklabels([\"pLDDT\"], fontsize=TICKS_FONTSIZE)\n",
        "    plddt_seg_ = np.full(SEGMENT_SIZE, np.nan)\n",
        "    plddt_seg_[:L_seg] = plddt_seg\n",
        "    im_plddt = ax_plddt.imshow(np.array([plddt_seg_]), cmap=cmap_plddt, norm=norm_plddt, aspect='equal')\n",
        "    for i, i_plddt in enumerate(plddt_seg):\n",
        "      if np.isnan(i_plddt): continue\n",
        "      ax_plddt.text(\n",
        "        i, 0, str(int(i_plddt)),\n",
        "        ha='center', va='center',\n",
        "        fontsize=VAL_FONTSIZE,\n",
        "      )\n",
        "\n",
        "    # Plot RSA\n",
        "    ax_rsa.set_xticks([])\n",
        "    ax_rsa.set_yticks([0])\n",
        "    ax_rsa.set_yticklabels([\"RSA\"], fontsize=TICKS_FONTSIZE)\n",
        "    rsa_seg_ = np.full(SEGMENT_SIZE, np.nan)\n",
        "    rsa_seg_[:L_seg] = rsa_seg\n",
        "    im_rsa = ax_rsa.imshow(np.array([rsa_seg_]), cmap=cmap_rsa, vmin=0, vmax=100, aspect='equal')\n",
        "    for i, i_rsa in enumerate(rsa_seg):\n",
        "      if np.isnan(i_rsa): continue\n",
        "      ax_rsa.text(\n",
        "        i, 0, str(int(i_rsa)),\n",
        "        ha='center', va='center',\n",
        "        fontsize=VAL_FONTSIZE,\n",
        "      )\n",
        "\n",
        "    # Plot average\n",
        "    ax_avg.set_xticks([])\n",
        "    ax_avg.set_yticks([0])\n",
        "    ax_avg.set_yticklabels([\"Mean\"], fontsize=TICKS_FONTSIZE)\n",
        "    vector_seg_ = np.full(SEGMENT_SIZE, np.nan)\n",
        "    vector_seg_[:L_seg] = vector_seg\n",
        "    im_avg = ax_avg.imshow(np.array([vector_seg_]), cmap=cmap, vmin=-extreme_val, vmax=extreme_val, aspect='equal')\n",
        "    for i, i_avg in enumerate(vector_seg):\n",
        "      if np.isnan(i_avg): continue\n",
        "      ax_avg.text(\n",
        "        i, 0, f\"{i_avg:.1f}\",\n",
        "        ha='center', va='center',\n",
        "        fontsize=VAL_FONTSIZE,\n",
        "      )\n",
        "\n",
        "    # Plot sdca values\n",
        "    matrix_img = np.full((A, SEGMENT_SIZE), np.nan, dtype=np.float32)\n",
        "    for i, wt_aa in enumerate(sequence_seg):\n",
        "      for j, mt_aa in enumerate(aas):\n",
        "        if wt_aa == mt_aa:\n",
        "          x = \"-\"\n",
        "          matrix_img[j, i] = np.nan\n",
        "        else:\n",
        "          matrix_img[j, i] = matrix_seg[j, i]\n",
        "          x_float = matrix_seg[j, i]\n",
        "          if np.isnan(x_float): continue\n",
        "          x = f\"{x_float:.1f}\"\n",
        "        ax0.text(\n",
        "          i, j, x,\n",
        "          ha='center', va='center',\n",
        "          fontsize=VAL_FONTSIZE,\n",
        "        )\n",
        "    im0 = ax0.imshow(matrix_img, cmap=cmap, vmin=-extreme_val, vmax=extreme_val, aspect='equal')\n",
        "    ax0.set_xticks([i for i in range(len(sequence_seg))])\n",
        "    ax0.set_xticklabels([f\"{sequence_seg[i]} {str(start+i+1)}\" for i in range(len(sequence_seg))], rotation=90, fontsize=TICKS_FONTSIZE)\n",
        "    ax0.set_yticks([i for i in range(A)])\n",
        "    ax0.set_yticklabels([aa for aa in aas], fontsize=TICKS_FONTSIZE)\n",
        "\n",
        "    # Save plot\n",
        "    heatmap_path = os.path.join(heatmap_dir, f\"{msa.name}_{prediction}_seg{n_seg+1}.png\")\n",
        "    plot_msg = (\n",
        "      f\"{prediction}\\n\"\n",
        "      f\" * {clip_string(msa.name, 50)}\\n\"\n",
        "      f\" * MSA: $L={L}$, $N={Ntot}$\\n\"\n",
        "      f\" * Range [{n_seg+1}/{len(segments)}]: {start+1} - {end}\"\n",
        "    )\n",
        "    plt.text(-5.0, 16.0, plot_msg, rotation=90, fontsize=NOTE_FONTSIZE, linespacing=1.5)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(heatmap_path, dpi=DPI)\n",
        "    plt.show()\n",
        "    plt.close();\n",
        "    print(f\"    - file saved to '{heatmap_path}' âœ…\")\n",
        "\n",
        "\n",
        "# Zip and download heatmaps ----------------------------------------------------\n",
        "\n",
        "# Zip heatmaps directory\n",
        "shutil.make_archive(heatmap_dir, \"zip\", heatmap_dir)\n",
        "\n",
        "# Download\n",
        "heatmap_zip_path = f\"{heatmap_dir}.zip\"\n",
        "files.download(heatmap_zip_path)\n",
        "print(f\"\\nâœ… RSALOR heatmaps plots '{heatmap_zip_path}' downloaded.\")\n"
      ],
      "metadata": {
        "id": "Ferrf-fsn6qA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}