{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## RSALOR: Ready-to-Use Notebook\n",
        "[![PyPi Version](https://img.shields.io/pypi/v/rsalor.svg)](https://pypi.org/project/rsalor/) [![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
        "https://colab.research.google.com/github/3BioCompBio/RSALOR/blob/main/colab_notebook_RSALOR.ipynb)\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/3BioCompBio/RSALOR/main/Logo.png\" height=\"250\" align=\"right\" style=\"height:200px;\">\n",
        "\n",
        "Ready-to-Use Notebook to run the RSALOR model:\n",
        " - Upload or fetch an MSA file\n",
        " - Uploae or fetch a 3D structure file\n",
        " - Run predictions on all single-site mutations\n",
        "\n",
        "The `rsalor` package combines structural data (Relative Solvent Accessibility, RSA) and evolutionary data (Log Odd Ratio, LOR from MSA) to evaluate effects of missense mutations in proteins.\n",
        "It computes the `RSA*LOR` score for each single-site missense mutation in a target protein by combining multiple computational steps into a fast and user-friendly tool.\n",
        "Source code in the [RSALOR GitHub](https://github.com/3BioCompBio/RSALOR).\n",
        "\n",
        "**Please cite**:\n",
        "- [Matsvei Tsishyn, Pauline Hermans, Fabrizio Pucci, Marianne Rooman (2025). Residue conservation and solvent accessibility are (almost) all you need for predicting mutational effects in proteins. Bioinformatics, btaf322](https://doi.org/10.1093/bioinformatics/btaf322).\n",
        "\n",
        "- [Pauline Hermans, Matsvei Tsishyn, Martin Schwersensky, Marianne Rooman, Fabrizio Pucci (2024). Exploring evolution to uncover insights into protein mutational stability. Molecular Biology and Evolution, 42(1), msae267](https://doi.org/10.1093/molbev/msae267)."
      ],
      "metadata": {
        "id": "igDhE0gKOOiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install dependencies\n",
        "\n",
        "%pip install rsalor\n",
        "%pip install requests"
      ],
      "metadata": {
        "cellView": "form",
        "id": "URoienkLfNsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzWtI1teMTTA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Imports and utility functions\n",
        "\n",
        "# Imports ----------------------------------------------------------------------\n",
        "import os\n",
        "import tarfile\n",
        "import time\n",
        "from typing import Callable\n",
        "import requests\n",
        "from requests import Response\n",
        "from google.colab import files\n",
        "from Bio.PDB import PDBParser, PPBuilder, PDBList\n",
        "from rsalor import MSA\n",
        "from rsalor.sequence import Sequence, FastaReader, PairwiseAlignment\n",
        "\n",
        "\n",
        "# Init paths -------------------------------------------------------------------\n",
        "# Set these paths to None to prevent the user to execute cells in incorrect order\n",
        "msa_path = None\n",
        "pdb_path = None\n",
        "chain = None\n",
        "output_path = None\n",
        "\n",
        "\n",
        "# Dependencies (small helper functions) ----------------------------------------\n",
        "def clip_string(input_str: str, max_len: int=100) -> str:\n",
        "  \"\"\"Truncate a string and append '...' if it exceeds max_len.\"\"\"\n",
        "  return input_str if len(input_str) <= max_len else input_str[:max_len] + \"...\"\n",
        "\n",
        "\n",
        "# Dependencies (fetch functions) -----------------------------------------------\n",
        "def is_valid_pdb_id(pdb_id :str) -> bool:\n",
        "  \"\"\"Returns if 'input' can be a PDB-ID.\"\"\"\n",
        "  POSSIBLE_FIRST_CHARACTERS = \"123456789\"\n",
        "  POSSIBLE_FOLLOWING_CHARACTERS = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "  input_upper = pdb_id.upper()\n",
        "  return len(input_upper) == 4 \\\n",
        "    and input_upper[0] in POSSIBLE_FIRST_CHARACTERS \\\n",
        "    and all([char in POSSIBLE_FOLLOWING_CHARACTERS for char in input_upper[1:]])\n",
        "\n",
        "def fetch_structure_by_pdb(pdb_id: str) -> str:\n",
        "  \"\"\"Fetch a '.pdb' file from the PDB and return its path.\"\"\"\n",
        "  pdb_id = pdb_id.lower().strip()\n",
        "  if not is_valid_pdb_id(pdb_id):\n",
        "    raise ValueError(f\"❌ pdb_id='{pdb_id}' is not a valid PDB Id.\")\n",
        "  pdb_fetcher = PDBList()\n",
        "  file_path = pdb_fetcher.retrieve_pdb_file(pdb_id, file_format=\"pdb\", pdir=\"./\")\n",
        "  if file_path is None:\n",
        "    raise ValueError(f\"❌ Fetch pdb_id='{pdb_id}' has failed.\")\n",
        "  if file_path.endswith(\".ent\"):\n",
        "    file_path_old = file_path\n",
        "    file_path = file_path.removesuffix(\".ent\") + \".pdb\"\n",
        "    os.rename(file_path_old, file_path)\n",
        "  return file_path\n",
        "\n",
        "def fetch_structure_by_uniprot(uniprot_id: str) -> str:\n",
        "  \"\"\"Fetch a '.pdb' file from the AlphaFoldDB by its UniProt ID and return its path.\"\"\"\n",
        "\n",
        "  # Init\n",
        "  uniprot_id = uniprot_id.upper().strip()\n",
        "  filename = f\"AF-{uniprot_id}-F1-model_v6.pdb\"\n",
        "  url = f\"https://alphafold.ebi.ac.uk/files/{filename}\"\n",
        "  print(f\" * fetch 3D structure from '{url}'\")\n",
        "\n",
        "  # Request structure\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "    r.raise_for_status()\n",
        "  except Exception as err:\n",
        "    raise ValueError(f\"❌ AlphaFoldDB structure fetch failed for UniProt ID '{uniprot_id}' from '{url}': {err}\")\n",
        "\n",
        "  # Save structure and return path\n",
        "  with open(filename, \"wb\") as fs:\n",
        "    fs.write(r.content)\n",
        "  return filename\n",
        "\n",
        "def fetch_msa_by_uniprot(uniprot_id: str) -> str:\n",
        "  \"\"\"Fetch an MSA file from the AlphaFoldDB by its UniProt ID and return its path.\"\"\"\n",
        "\n",
        "  # Init\n",
        "  uniprot_id = uniprot_id.upper().strip()\n",
        "  filename = f\"AF-{uniprot_id}-F1-msa_v6.a3m\"\n",
        "  url = f\"https://alphafold.ebi.ac.uk/files/msa/{filename}\"\n",
        "  print(f\" * fetch MSA from '{url}'\")\n",
        "\n",
        "  # Steam and write MSA to file and return path\n",
        "  try:\n",
        "    with requests.get(url, stream=True) as resp:\n",
        "      resp.raise_for_status()\n",
        "      with open(filename, \"wb\") as fs:\n",
        "        for chunk in resp.iter_content(1 << 14): # 16 KB chunks\n",
        "          if chunk:\n",
        "            fs.write(chunk)\n",
        "  except Exception as err:\n",
        "    raise ValueError(f\"❌ AlphaFoldDB MSA fetch failed for UniProt ID '{uniprot_id}': download failed from '{url}': {err}\")\n",
        "  return filename\n",
        "\n",
        "def fetch_sequence_by_uniprot(uniprot_id: str) -> str:\n",
        "  \"\"\"Fetch an FASTA sequence from UniProt by its UniProt ID and return its path.\"\"\"\n",
        "\n",
        "  # Init\n",
        "  uniprot_id = uniprot_id.upper().strip()\n",
        "  filename = f\"{uniprot_id}.fasta\"\n",
        "  url = f\"https://rest.uniprot.org/uniprotkb/{filename}\"\n",
        "  print(f\" * fetch FASTA sequence from '{url}'\")\n",
        "\n",
        "  # Request fasta\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "    r.raise_for_status()\n",
        "  except Exception as err:\n",
        "    raise ValueError(f\"❌ UniProt FASTA sequence fetch failed for UniProt ID '{uniprot_id}' from '{url}': {err}\")\n",
        "\n",
        "  # Save fasta and return path\n",
        "  with open(filename, \"wb\") as fs:\n",
        "    fs.write(r.content)\n",
        "  return filename\n",
        "\n",
        "# Dependencies (MMSeqs2 API) ---------------------------------------------------\n",
        "\n",
        "def repeated_request(request_function: Callable):\n",
        "  \"\"\"Decorator to repeat a request 5 times before trowing an error.\"\"\"\n",
        "\n",
        "  def wrapper(*args, **kwargs) -> Response:\n",
        "    MAX_REQUEST_TRIES = 5\n",
        "    FAIL_SLEEP_TIME = 5.0\n",
        "    print(f\" * Request [{request_function.__name__}] for '{clip_string(args[0])}' ({MAX_REQUEST_TRIES} repeats)\")\n",
        "    for i in range(MAX_REQUEST_TRIES):\n",
        "      print(f\"   - [{request_function.__name__}] repeat [{i+1}/{MAX_REQUEST_TRIES}] ...\")\n",
        "      try:\n",
        "        res: Response = request_function(*args, **kwargs)\n",
        "      except Exception as err:\n",
        "        print(f\"   - [{request_function.__name__}] Error on attempt [{i+1}/{MAX_REQUEST_TRIES}]: {err}\")\n",
        "        time.sleep(FAIL_SLEEP_TIME)\n",
        "      else:\n",
        "        print(f\"   - [{request_function.__name__}] status: {res.status_code}\")\n",
        "        return res\n",
        "    raise ValueError(f\"Too many failed attempts ({MAX_REQUEST_TRIES}) for request '{request_function.__name__}'.\")\n",
        "\n",
        "  return wrapper\n",
        "\n",
        "def json_request(request_function: Callable):\n",
        "  \"\"\"Decorator run a request and parse output as JSON if possible.\"\"\"\n",
        "\n",
        "  def wrapper(*args, **kwargs):\n",
        "    res: Response = request_function(*args, **kwargs)\n",
        "    try:\n",
        "      return res.json()\n",
        "    except Exception as err:\n",
        "      msg = (\n",
        "        f\"Failed to parse response from '{request_function.__name__}' as JSON.\\n\"\n",
        "        f\"Original error: {err}\\n\"\n",
        "        f\"HTTP status: {res.status_code}\\n\"\n",
        "        f\"Response (truncated): {clip_string(res.text)}\"\n",
        "      )\n",
        "      raise ValueError(msg) from err\n",
        "\n",
        "  return wrapper\n",
        "\n",
        "@json_request\n",
        "@repeated_request\n",
        "def submit_mmseqs2(seq: str, mode: str, url: str, endpoint: str, timeout: float, query_name: str=\"query\"):\n",
        "  query_name = query_name.strip().replace(\" \", \"_\").replace(\"\\t\", \"_\").replace(\"\\n\", \"_\")\n",
        "  assert len(query_name) > 0, f\"ERROR in submit_mmseqs2(): invalid query_name='{query_name}'\"\n",
        "  return requests.post(\n",
        "    f\"{url}/{endpoint}\",\n",
        "    data={\"q\": f\">{query_name}\\n{seq}\\n\", \"mode\": mode},\n",
        "    timeout=timeout,\n",
        "  )\n",
        "\n",
        "@json_request\n",
        "@repeated_request\n",
        "def get_mmseqs2_status(id: str, url: str, timeout: float):\n",
        "  res = requests.get(\n",
        "    f\"{url}/ticket/{id}\",\n",
        "    timeout=timeout,\n",
        "  )\n",
        "  return res\n",
        "\n",
        "@repeated_request\n",
        "def download_from_mmseqs2(id: str, url: str, timeout: float) -> Response:\n",
        "  res = requests.get(\n",
        "    f\"{url}/result/download/{id}\",\n",
        "    timeout=timeout,\n",
        "  )\n",
        "  return res\n",
        "\n",
        "class MMSeqs2API:\n",
        "\n",
        "  # Constructor\n",
        "  def __init__(\n",
        "    self,\n",
        "    tmp_dir: str,\n",
        "    n_status_loop: int=100,\n",
        "    loop_timeout: float = 5.0,\n",
        "    single_request_timeout: float=6.02,\n",
        "    use_env: bool = False,\n",
        "    use_filter: bool = True,\n",
        "    url: str=\"https://api.colabfold.com\",\n",
        "    endpoint: str=\"ticket/msa\",\n",
        "  ):\n",
        "\n",
        "    # Set properties\n",
        "    self.tmp_dir = tmp_dir\n",
        "    self.url = url\n",
        "    self.endpoint = endpoint\n",
        "    self.n_status_loop = n_status_loop\n",
        "    self.loop_timeout = loop_timeout\n",
        "    self.single_request_timeout = single_request_timeout\n",
        "    self.use_env = use_env\n",
        "    self.use_filter = use_filter\n",
        "    if self.use_filter:\n",
        "      self.mode = \"env\" if self.use_env else \"all\"\n",
        "    else:\n",
        "      self.mode = \"env-nofilter\" if self.use_env else \"nofilter\"\n",
        "\n",
        "    # Init tmp directory\n",
        "    if not os.path.isdir(self.tmp_dir):\n",
        "      os.mkdir(self.tmp_dir)\n",
        "\n",
        "    # Init paths\n",
        "    self.tar_gz_file = os.path.join(self.tmp_dir, \"out.tar.gz\")\n",
        "    if not self.use_env:\n",
        "      self.a3m_files = [os.path.join(self.tmp_dir, \"uniref.a3m\")]\n",
        "    else:\n",
        "      self.a3m_files = [\n",
        "        os.path.join(self.tmp_dir, \"uniref.a3m\"),\n",
        "        os.path.join(self.tmp_dir, \"bfd.mgnify30.metaeuk30.smag30.a3m\")\n",
        "      ]\n",
        "\n",
        "  # Run API\n",
        "  def run(\n",
        "    self,\n",
        "    sequence: str,\n",
        "    save_path: str,\n",
        "    query_name: str=\"query\",\n",
        "  ) -> str:\n",
        "\n",
        "    # Log\n",
        "    print(f\"Run MSA API to MMSeqs2 server '{self.url}/{self.endpoint}': \")\n",
        "    print(f\"   - sequence: '{clip_string(sequence)}'\")\n",
        "    print(f\"   - save_path: '{save_path}'\")\n",
        "\n",
        "    # Submit to MMSeqs2 API\n",
        "    print(\"Submit request:\")\n",
        "    out = submit_mmseqs2(sequence, self.mode, self.url, self.endpoint, self.single_request_timeout, query_name=query_name)\n",
        "    status, id = out[\"status\"], out[\"id\"]\n",
        "    if status in [\"ERROR\", \"MAINTENANCE\"]:\n",
        "      raise Exception(f\"MMseqs2 API is giving errors with API status: '{status}' (please try again later)\")\n",
        "\n",
        "    # Wait for request to be completed\n",
        "    print(\"Wait for request to be completed:\")\n",
        "    for i in range(self.n_status_loop):\n",
        "      if status not in [\"UNKNOWN\", \"RUNNING\", \"PENDING\"]:\n",
        "        break\n",
        "      print(f\"   - sleep [{i+1}/{self.n_status_loop}] for {self.loop_timeout:.1f} sec. (status='{status}') ...\")\n",
        "      time.sleep(self.loop_timeout)\n",
        "      out = get_mmseqs2_status(id, self.url, self.single_request_timeout)\n",
        "      status = out[\"status\"]\n",
        "\n",
        "    # Status loop finished and request still not complete\n",
        "    if status in [\"UNKNOWN\", \"RUNNING\", \"PENDING\"]:\n",
        "      msg = (\n",
        "        f\"MMseqs2 API ERROR: maximum number of sleep loop exceeded.\\n\"\n",
        "        f\" - {self.n_status_loop} loops (of {self.loop_timeout:.1f} sec. each)\\n\"\n",
        "        f\" - request ID='{id}'\\n\"\n",
        "      )\n",
        "      raise Exception(msg)\n",
        "\n",
        "    # Final API status check\n",
        "    if status != \"COMPLETE\":\n",
        "      raise Exception(f\"MMseqs2 API is giving errors with API status: '{status}' (please try again later)\")\n",
        "\n",
        "    # Download results\n",
        "    print(\"Download MSA:\")\n",
        "    download_output = download_from_mmseqs2(id, self.url, self.single_request_timeout)\n",
        "    with open(self.tar_gz_file, \"wb\") as fs:\n",
        "      fs.write(download_output.content)\n",
        "\n",
        "    # Extract a3m files from '.tar.gz'\n",
        "    print(f\"Collect MSA data:\")\n",
        "    with tarfile.open(self.tar_gz_file) as tar_gz:\n",
        "      tar_gz.extractall(self.tmp_dir, filter=\"data\")\n",
        "\n",
        "    # Collect and return all '.a3m' lines\n",
        "    a3m_lines: list[str] = []\n",
        "    for a3m_file in self.a3m_files:\n",
        "      for line in open(a3m_file, \"r\"):\n",
        "        if len(line) == 0: continue\n",
        "        line = line.replace(\"\\x00\", \"\")\n",
        "        a3m_lines.append(line)\n",
        "    msa_str = \"\".join(a3m_lines)\n",
        "\n",
        "    # Save MSA to file\n",
        "    print(f\"Save MSA to file:\")\n",
        "    print(f\"   - save_path: '{save_path}'\")\n",
        "    with open(save_path, \"w\") as fs:\n",
        "      fs.write(msa_str)\n",
        "\n",
        "    # Return\n",
        "    return save_path\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3D Structure options (upload file or fetch from PDB or AlphaFold-DB)\n",
        "\n",
        "# Define upload method ---------------------------------------------------------\n",
        "upload_method = \"upload_local_file\" # @param [\"upload_local_file\",\"fetch_from_pdb\",\"fetch_from_alphafold_db\"]\n",
        "#@markdown ---------------------------------------------------------------------\n",
        "retrieval_id = \"\" # @param {\"type\":\"string\",\"placeholder\":\"PDB ID like '6m0j' or UniProt ID like 'Q9LW00'\"}\n",
        "#@markdown - if using `fetch_from_pdb`, specify a **PDB ID** (like `6m0j`)\n",
        "#@markdown - if using `fetch_from_alphafold_db`, specify a **UniProt ID** (like `Q9LW00`)\n",
        "\n",
        "\n",
        "# Case: Drag-and-drop local file -----------------------------------------------\n",
        "pdb_path = None\n",
        "if upload_method == \"upload_local_file\":\n",
        "\n",
        "  # Drag-and-drop file picker\n",
        "  uploaded = files.upload()\n",
        "  pdb_path: str = list(uploaded.keys())[0]\n",
        "\n",
        "  # Guardian for correct extension\n",
        "  if not pdb_path.endswith(\".pdb\"):\n",
        "    pdb_path_failed = pdb_path\n",
        "    pdb_path = None\n",
        "    raise ValueError(f\"❌ Uploaded PDB file '{pdb_path_failed}' should have extention '.pdb'.\")\n",
        "  pdb_name = pdb_path.removesuffix(\".pdb\")\n",
        "  print(f\" * ✅ PDB file uploaded: '{pdb_path}'\")\n",
        "\n",
        "# Case: fetch file from the PDB ------------------------------------------------\n",
        "elif upload_method == \"fetch_from_pdb\":\n",
        "\n",
        "  # retrieval_id not fill error\n",
        "  if retrieval_id == \"\" or retrieval_id is None:\n",
        "    raise ValueError(f\"❌ If upload_method='{upload_method}', please specify a retrieval_id.\")\n",
        "\n",
        "  # Fetch PDB file\n",
        "  pdb_path: str = fetch_structure_by_pdb(retrieval_id)\n",
        "  pdb_name = pdb_path.removesuffix(\".pdb\")\n",
        "  print(f\" * ✅ PDB file fetched: '{pdb_path}'\")\n",
        "\n",
        "# Case: fetch file from the AlphaFold-DB ---------------------------------------\n",
        "elif upload_method == \"fetch_from_alphafold_db\":\n",
        "\n",
        "  # retrieval_id not fill error\n",
        "  if retrieval_id == \"\" or retrieval_id is None:\n",
        "    raise ValueError(f\"❌ If upload_method='{upload_method}', please specify a retrieval_id.\")\n",
        "\n",
        "  # Fetch PDB file\n",
        "  pdb_path: str = fetch_structure_by_uniprot(retrieval_id)\n",
        "  pdb_name = pdb_path.removesuffix(\".pdb\")\n",
        "  print(f\" * ✅ AF-DB file fetched: '{pdb_path}'\")\n",
        "\n",
        "# Case: error ------------------------------------------------------------------\n",
        "else:\n",
        "  raise ValueError(f\"❌ Unknown upload_method='{upload_method}'.\")\n",
        "\n",
        "# Validate and Log -------------------------------------------------------------\n",
        "# Parse PDB file\n",
        "pp_builer = PPBuilder()\n",
        "structure = PDBParser(QUIET=True).get_structure(\"protein\", pdb_path)\n",
        "\n",
        "# Log uploaded PDB file\n",
        "sequences_by_chain: dict[str, Sequence] = {}\n",
        "for chain in structure[0]: # loop only on model 1\n",
        "  aa_seq_segments: list[str] = pp_builer.build_peptides(chain)\n",
        "  aa_seq: str = \"\".join([str(pp.get_sequence()) for pp in aa_seq_segments]) # concatenate fragments if multiple\n",
        "  print(f\"    - chain {chain.id} (L={len(aa_seq)}): '{aa_seq}'\")\n",
        "  sequences_by_chain[chain.id] = Sequence(f\"{pdb_name}_{chain.id}\", aa_seq)\n",
        "print(f\" * ✅ Choose target chain among {len(sequences_by_chain)} detected chain(s): '{''.join(sequences_by_chain.keys())}'\")\n",
        "\n",
        "# Select chain if there is only one\n",
        "if len(sequences_by_chain) == 1:\n",
        "  chain = list(sequences_by_chain.keys())[0]\n",
        "  print(f\" * ✅ Target chain set to: chain='{chain}'\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "O6dopoi7ivAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title MSA options (upload file, fetch from AlphaFold-DB or run MMSeqs2 API)\n",
        "\n",
        "# Define upload method ---------------------------------------------------------\n",
        "upload_method = \"upload_local_file\" # @param [\"upload_local_file\",\"fetch_from_alphafold_db\",\"run_mmseqs2_api\"]\n",
        "#@markdown ---------------------------------------------------------------------\n",
        "uniprot_id = \"\" # @param {\"type\":\"string\",\"placeholder\":\"UniProt ID like 'Q9LW00'\"}\n",
        "#@markdown - if using `fetch_from_alphafold_db`, specify a **UniProt ID** (like `Q9LW00`)\n",
        "#@markdown ---------------------------------------------------------------------\n",
        "query_sequence = \"\" # @param {\"type\":\"string\",\"placeholder\":\"protein sequence like 'VSVELPAPSSWKKLFYPNKVGSVKKTEVVFVAPTGEEISNRKQLEQYLKSHPGNPAIAEFDWTTSG'\"}\n",
        "#@markdown - if using `run_mmseqs2_api`, specify a protein sequence\n",
        "query_name = \"query_sequence_1\" # @param {\"type\":\"string\",\"placeholder\":\"set name of the query sequence\"}\n",
        "mmseqs2_use_filtering = True # @param {\"type\":\"boolean\"}\n",
        "mmseqs2_use_environmental_sequences = False # @param {\"type\":\"boolean\"}\n",
        "\n",
        "# Case: Drag-and-drop local file -----------------------------------------------\n",
        "msa_path = None\n",
        "if upload_method == \"upload_local_file\":\n",
        "\n",
        "  # Drag-and-drop file picker\n",
        "  uploaded = files.upload()\n",
        "  msa_path: str = list(uploaded.keys())[0]\n",
        "\n",
        "  # Guardian for correct extension\n",
        "  if not any(msa_path.endswith(ext) for ext in MSA.ACCEPTED_EXTENTIONS):\n",
        "      msa_path_failed = msa_path\n",
        "      msa_path = None\n",
        "      raise ValueError(f\"❌ Uploaded MSA file '{msa_path_failed}' should have extention among {MSA.ACCEPTED_EXTENTIONS}.\")\n",
        "  print(f\" * ✅ MSA file uploaded: '{msa_path}'\")\n",
        "\n",
        "# Case: fetch file from the AlphaFold-DB ---------------------------------------\n",
        "elif upload_method == \"fetch_from_alphafold_db\":\n",
        "\n",
        "  # retrieval_id not fill error\n",
        "  if uniprot_id == \"\" or uniprot_id is None:\n",
        "    raise ValueError(f\"❌ If upload_method='{upload_method}', please specify a uniprot_id.\")\n",
        "\n",
        "  # Fetch PDB file\n",
        "  msa_path: str = fetch_msa_by_uniprot(uniprot_id)\n",
        "  print(f\" * ✅ MSA file fetched from AF-DB: '{msa_path}'\")\n",
        "\n",
        "# Case: run MMSeqs2 API --------------------------------------------------------\n",
        "elif upload_method == \"run_mmseqs2_api\":\n",
        "\n",
        "  # Pre-process query_sequence\n",
        "  query_sequence = query_sequence.strip().replace(\" \", \"\").upper()\n",
        "  if query_sequence == \"\" or query_sequence is None:\n",
        "    raise ValueError(f\"❌ If upload_method='{upload_method}', please specify a query_sequence.\")\n",
        "  if not all([aa in \"ACDEFGHIKLMNPQRSTVWY\" for aa in query_sequence]):\n",
        "    raise ValueError(f\"❌ query_sequence contains invalid amino acids.\")\n",
        "  query_name = query_name.strip().replace(\" \", \"_\")\n",
        "  if query_name == \"\" or query_name is None:\n",
        "    raise ValueError(f\"❌ If upload_method='{upload_method}', please specify a query_name.\")\n",
        "\n",
        "  # Run MMSeqs2 API\n",
        "  api = MMSeqs2API(\n",
        "    f\"./{query_name}_mmseqs2_out\",\n",
        "    use_env=mmseqs2_use_environmental_sequences,\n",
        "    use_filter=mmseqs2_use_filtering,\n",
        "  )\n",
        "  msa_path: str = api.run(query_sequence, f\"./{query_name}.a3m\", query_name)\n",
        "  print(f\" * ✅ MSA file obtained from MMSeqs2 API: '{msa_path}'\")\n",
        "\n",
        "# Case: error ------------------------------------------------------------------\n",
        "else:\n",
        "  raise ValueError(f\"❌ Unknown upload_method='{upload_method}'.\")\n",
        "\n",
        "# Validate and Log -------------------------------------------------------------\n",
        "taget_sequence = FastaReader.read_first_sequence(msa_path)\n",
        "print(f\" * ✅ taget sequence (L={len(taget_sequence)}): '{taget_sequence.sequence}'\")\n",
        "\n"
      ],
      "metadata": {
        "id": "iKcd15dHQySw",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select PDB chain\n",
        "chain = \"\" # @param {\"type\":\"string\",\"placeholder\":\"select a single chains like 'A'\"}\n",
        "\n",
        "# Input guardians\n",
        "if msa_path == \"\" or msa_path is None:\n",
        "  raise ValueError(f\"❌ ERROR: msa_path is not set: Please first select an MSA.\")\n",
        "if pdb_path == \"\" or pdb_path is None:\n",
        "  raise ValueError(f\"❌ ERROR: pdb_path is not set: Please first, select a 3D structure.\")\n",
        "\n",
        "# Guardians\n",
        "if len(chain) != 1:\n",
        "  chain_failed = chain\n",
        "  chain = None\n",
        "  raise ValueError(f\"❌ chain='{chain_failed}' should be a string of length 1.\")\n",
        "if chain not in sequences_by_chain:\n",
        "  chain_failed = chain\n",
        "  chain = None\n",
        "  raise ValueError(f\"❌ chain='{chain_failed}' not in PDB '{pdb_path}' (among chains '{''.join(sequences_by_chain.keys())}')\")\n",
        "\n",
        "# Show alignments\n",
        "print(f\" * ✅ MSA target sequence aligned to chain '{chain}' in PDB structure.\")\n",
        "align = PairwiseAlignment(taget_sequence, sequences_by_chain[chain])\n",
        "align.show();\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yTKvX4WCz9W9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run RSALOR and Settings\n",
        "\n",
        "# Output settings\n",
        "#@markdown ### Output settings\n",
        "output_name = \"\" # @param {\"type\":\"string\",\"placeholder\":\"<msa_name>_rsalor\"}\n",
        "#@markdown - leave empty for auto\n",
        "sep = \",\" # @param {\"type\":\"string\",\"placeholder\":\"CSV separator like ',' or ';'\"}\n",
        "#@markdown - separator in output CSV file\n",
        "\n",
        "# RSALOR run settings\n",
        "#@markdown ---------------------------------------------------------------------\n",
        "#@markdown ### RSALOR settings\n",
        "theta_regularization = 0.01 # @param {\"type\":\"number\",\"placeholder\":\"0.01\"}\n",
        "#@markdown - regularization term for LOR/LR at amino acid frequencies level\n",
        "seqid_weights = 0.80 # @param {\"type\":\"number\",\"placeholder\":\"0.80\"}\n",
        "#@markdown - seqid threshold to consider two sequences in the same cluster for weighting (leave empty to ignore)\n",
        "min_seqid = 0.35 # @param {\"type\":\"number\",\"placeholder\":\"0.35\"}\n",
        "#@markdown - discard sequences which seqid with target sequence is below (leave empty to ignore)\n",
        "num_threads = 2 # @param {\"type\":\"integer\",\"placeholder\":\"2\"}\n",
        "#@markdown - number of threads (CPUs) for weights evaluation (in the C++ backend)\n",
        "\n",
        "# Input guardians\n",
        "if msa_path == \"\" or msa_path is None:\n",
        "  raise ValueError(f\"❌ ERROR: msa_path is not set: Please first select an MSA.\")\n",
        "if pdb_path == \"\" or pdb_path is None:\n",
        "  raise ValueError(f\"❌ ERROR: pdb_path is not set: Please first, select a 3D structure.\")\n",
        "if chain == \"\" or chain is None:\n",
        "  raise ValueError(f\"❌ ERROR: chain is not set: Please first, select a chain.\")\n",
        "\n",
        "# Run RSALOR\n",
        "output_path = None\n",
        "msa = MSA(\n",
        "    msa_path, pdb_path, chain,\n",
        "    theta_regularization=theta_regularization,\n",
        "    seqid_weights=seqid_weights,\n",
        "    min_seqid=min_seqid,\n",
        "    num_threads=num_threads,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Set output path\n",
        "if output_name == \"\" or output_name is None:\n",
        "  output_name = f\"{msa.name}_rsalor\"\n",
        "output_path = f\"{output_name}.csv\"\n",
        "\n",
        "# Compute and save scores\n",
        "rsalor_scores = msa.save_scores(\n",
        "    output_path,\n",
        "    sep=sep,\n",
        "    round_digit=6,\n",
        "    log_results=False,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Ebp05L4F7p3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download RSALOR output\n",
        "\n",
        "# Input guardians\n",
        "if output_path == \"\" or output_path is None:\n",
        "  raise ValueError(f\"❌ ERROR: output_path is not set: Please first run RSALOR.\")\n",
        "\n",
        "# Download\n",
        "files.download(output_path)"
      ],
      "metadata": {
        "id": "KmW_SkOqEGuG",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}